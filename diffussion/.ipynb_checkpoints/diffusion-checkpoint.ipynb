{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e1dd9d-eb08-4c16-8010-d668ced8235b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11660/2956046627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.autoinit\n",
    "\n",
    "cuda_code =  SourceModule(\"\"\"\n",
    "     #include <stdio.h>\n",
    "\n",
    "   __device__ inline int pbc(int x, int L);\n",
    "   \n",
    "   __global__ void diffusion(double *arr_in, \n",
    "                             double *arr_out,\n",
    "                             double D,\n",
    "                             int nr, \n",
    "                             int nc)\n",
    "    {\n",
    "      \n",
    "      int i = threadIdx.x+ blockIdx.x* blockDim.x;\n",
    "      int j = threadIdx.y+ blockIdx.y* blockDim.y;\n",
    "      //arr_out[j + i*nc] = 2.0;\n",
    "\n",
    "      int n = pbc(i-1,nr);\n",
    "      int s = pbc(i+1,nr);\n",
    "      int w = pbc(j-1,nc);\n",
    "      int e = pbc(j+1,nc);\n",
    "\n",
    "      arr_out[i*nc+j] =  arr_in[i*nc+j] +\n",
    "                         D*(arr_in[n*nc+j] + arr_in[s*nc+j] +\n",
    "                            arr_in[i*nc+w] + arr_in[i*nc+e] -\n",
    "                            4.0*arr_in[i*nc+j]);\n",
    "    }\n",
    "\n",
    "    __device__ inline int pbc(int x, int L)\n",
    "    {\n",
    "        return  x - (int)floor((double)x/L)*L;\n",
    "    }\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def plot_heat_map(matrix, mx, mn, save=False, id=0):\n",
    "  \"\"\"\n",
    "      plot_heat_map\n",
    "      Plots a heatmap or save it to file\n",
    "      \n",
    "      Input:    matrix = 2D array to reppresent\n",
    "                mx = max value to scale\n",
    "                mn = min value to scale\n",
    "                save = Boolean to indicate if is saved or reppresented\n",
    "                id = If saved the file is going to be saved with id + name\n",
    "  \"\"\"\n",
    "  # Show the array\n",
    "  fig = plt.figure()\n",
    "  hm=plt.imshow(matrix, \n",
    "                cmap='gray', \n",
    "                interpolation ='none', \n",
    "                aspect = 'auto',  \n",
    "                vmin=mn, vmax=mx)\n",
    "  plt.colorbar(hm)\n",
    "  plt.axes().set_aspect(1.0)\n",
    "\n",
    "  if save==False:\n",
    "    plt.show()\n",
    "  else:\n",
    "    plt.savefig(\"./figs/\" + str(id) + \"_diffusion.png\")   \n",
    "\n",
    "\n",
    "\n",
    "def initilise_array(arr, h, w, r, c0):\n",
    "  \"\"\"\n",
    "      initialise_array\n",
    "      Generates a drop in the middle of the array\n",
    "\n",
    "      Input:    arr = w x h array to initialise\n",
    "                h = height, number of rows\n",
    "                w = width, number of columns\n",
    "                r = radius of the drop\n",
    "                c0 = Initial concentration\n",
    "\n",
    "      Ouput     arr = Output array with the drop\n",
    "  \"\"\"\n",
    "\n",
    "  wh2 = w//2\n",
    "  hh2 = h//2\n",
    "  for i in range(0,h):\n",
    "    for j in range(0,w):\n",
    "      x=i-hh2\n",
    "      y=j-wh2\n",
    "      if(np.sqrt(x**2 + y**2)<r):\n",
    "        arr[i,j] = c0\n",
    "\n",
    "\n",
    "\n",
    "def diffusion(w, h, D, maxtime):\n",
    "  \"\"\"\n",
    "      diffusion\n",
    "      This function calls to the CUDA module to calculate the laplacian and the\n",
    "      ensuing diffusion\n",
    "\n",
    "      Input:       h = height, number of rows\n",
    "                   w = width, number of columns\n",
    "                   D = Diffusion constant (expressed in units of latice sites)\n",
    "                   maxtime = Number of iterations\n",
    "  \"\"\"\n",
    "  # We need to transform ints to numpy int to be readable by CUDA\n",
    "  w=np.int32(w)\n",
    "  h=np.int32(h)\n",
    "\n",
    "  # Get the function from the CUDA module\n",
    "  laplacian = cuda_code.get_function(\"diffusion\") \n",
    "\n",
    "\n",
    "  # Allocate data in the computer + initilisation\n",
    "  arr = np.zeros((h,w), dtype=np.float64)\n",
    "  c0 = 10.0\n",
    "  r = 60\n",
    "  initilise_array(arr, h, w, r, c0)\n",
    "  plot_heat_map(arr, c0, 0.0, save=False)\n",
    "  \n",
    "  # Allocate memory for the array in the GPU\n",
    "  arr_gpu     = cuda.mem_alloc(arr.nbytes) \n",
    "  arr_upd_gpu = cuda.mem_alloc(arr.nbytes) \n",
    "  cuda.memcpy_htod(arr_gpu, arr)\n",
    "\n",
    "  # Iterate the function on the GPU \n",
    "  # We first define the minimal unit ie, the block size. A grid is then a \n",
    "  # a collection of blocks, so we attribute a number of blocks that divisible with \n",
    "  # with the block size considering the size of the array. \n",
    "  bw=32   \n",
    "  bh=32\n",
    "  gw=int(np.floor(w/bw))\n",
    "  gh=int(np.floor(h/bh))\n",
    "\n",
    "  for t in range(0, maxtime):\n",
    "    # Send data from computer to GPU \n",
    "    cuda.memcpy_htod(arr_gpu, arr)\n",
    "\n",
    "    # Execute the function on the GPU \n",
    "    laplacian(arr_gpu, arr_upd_gpu, D, h, w, block=(bw,bh,1), grid=(gw,gh))\n",
    "    \n",
    "    # Retrieve the data from the GPU to the computer\n",
    "    cuda.memcpy_dtoh(arr, arr_upd_gpu)\n",
    "\n",
    "   \n",
    "  plot_heat_map(arr, c0, 0.0, save=False)\n",
    "  return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "D = np.float64(0.1) # np.float64 becuase every parameter to CUDA needs the variable type)\n",
    "w = 512\n",
    "h = 512\n",
    "maxtime = 5000\n",
    "diffusion(w, h, D, maxtime);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10927c1a-728c-4b62-80cc-32d1f633f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install pycuda\n",
    "#pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdc4a6-840e-4e7b-80a2-f8252e61af92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
